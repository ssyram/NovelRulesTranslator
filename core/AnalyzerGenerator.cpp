//
//  AnalyzerGenerator.cpp
//  NovelRulesTranslator
//
//  Created by 潇湘夜雨 on 2019/2/25.
//  Copyright © 2019 ssyram. All rights reserved.
//

#include "AnalyzerGenerator.hpp"

namespace rules_translator {
    void generateAnalyzer(FileInteractor &fi, CommandObject &cmd, utils::Logger &logger) {
        const static char *analyzer =
        "struct AnalyzeException { };\n"
        "#ifdef TEST\n"
        "struct Logger {\n"
        "    ostream &os;\n"
        "    template <typename ...Args>\n"
        "    Logger &operator()(Args ...msgs) {\n"
        "        (os << ... << msgs) << endl;\n"
        "        return *this;\n"
        "    }\n"
        "};\n"
        "#endif\n"
        "\n"
        "using std::pair;\n"
        "class SyntacticAnalyzer {\n"
        "#ifdef TEST\n"
        "    Logger logger;\n"
        "#endif\n"
        "    // the analyze stacks\n"
        "    stack<pair<size_t, symbol_type>> astack;\n"
        "    pass_info &info;\n"
        "\n"
        "public:\n"
        "    void init() {\n"
        "        astack.emplace(1, symbol_type{\n"
        "            utils::raw_type_map - utils::type_name_map, default_object_type{}\n"
        "        });\n"
        "    }\n"
        "#ifdef TEST\n"
        "    SyntacticAnalyzer(ostream &os, pass_info &info): logger{os}, info(info) {\n"
        "        init();\n"
        "    }\n"
        "#endif\n"
        "    SyntacticAnalyzer(pass_info &info): info(info)\n"
        "#ifdef TEST\n"
        "    , logger{cout}\n"
        "#endif\n"
        "    {\n"
        "        init();\n"
        "    }\n"
        "    SyntacticAnalyzer &operator()(const token_type *token) {\n"
        "        analyze(token);\n"
        "        return *this;\n"
        "    }\n"
        "    void analyze(const token_type *token_ptr) {\n"
        "        ll sym_type = token_ptr ? ll(get_type(*token_ptr)) : eof;\n"
        "#ifdef TEST\n"
        "        logger(\"Condition <\", astack.top().first, \"> Received '\", utils::type_name_map[sym_type], \"':\");\n"
        "#endif\n"
        "        ll next_action = action_table[astack.top().first][sym_type];\n"
        "        while (next_action < 0) { // do all reduce\n"
        "            const size_t POP_SIZE = pop_size_map[-next_action];\n"
        "            vector<symbol_type> right(POP_SIZE);\n"
        "            for (size_t i = 0; i < POP_SIZE; ++i) {\n"
        "                right[POP_SIZE - 1 - i] = std::move(astack.top().second);\n"
        "                astack.pop();\n"
        "            }\n"
        "            ll left_type = left_map[-next_action];\n"
        "            // to access goto table, \"-symbol - 1\"\n"
        "            size_t condition = goto_table[astack.top().first][-left_type - 1];\n"
        "            if (!condition) throw \"This should not happen\";\n"
        "            astack.emplace(condition, semantic_list[-next_action](left_type, right, info));\n"
        "            next_action = action_table[astack.top().first][sym_type];\n"
        "#ifdef TEST\n"
        "            logger(\"REDUCE to symbol: \", utils::type_name_map[left_type],\n"
        "                   \", Condition <\", condition, '>');\n"
        "#endif\n"
        "        } // end reduce\n"
        "        if (!next_action)\n"
        "            throw AnalyzeException{};\n"
        "        astack.emplace(next_action, token_ptr ? symbol_type{sym_type, *token_ptr} : symbol_type{});\n"
        "#ifdef TEST\n"
        "        logger(\"Accept '\", utils::type_name_map[sym_type], \"' SHIFT to \", next_action)\n"
        "        (\"=========================================================================\")\n"
        "        ();\n"
        "#endif\n"
        "    }\n"
        "};\n"
        "\n"
        "template <typename T, typename ...InitArgs>\n"
        "pass_info analyze(const T &token_stream,\n"
        "#ifdef TEST\n"
        "                  ostream &os = cout,\n"
        "#endif\n"
        "                  InitArgs &&...args) {\n"
        "    pass_info r(std::forward<InitArgs>(args)...);\n"
        "    SyntacticAnalyzer analyzer(\n"
        "#ifdef TEST\n"
        "                               os,\n"
        "#endif\n"
        "                               r);\n"
        "    for (auto &token: token_stream) {\n"
        "        analyzer(&token);\n"
        "    }\n"
        "    analyzer(nullptr);\n"
        "    return r;\n"
        "}";
        fi.writeln(analyzer);
    }
}
